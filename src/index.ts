/**
 * MongoDB Zero-Downtime Index Rebuilder
 *
 * Universal rebuild script ported from mongosh to TypeScript.
 * Implements the Cover-Swap-Cleanup strategy with dual verification,
 * cluster awareness, state file resumability, and interactive prompts.
 */

import { Db, Collection, MongoClient } from 'mongodb';
import {
  RebuildConfig,
  RebuildState,
  IndexStat,
  IndexLog,
  CollectionLog,
  DatabaseLog,
  OrphanedIndex,
  RebuildPaths,
  CollectionInfo,
  IndexDocument,
  VALID_INDEX_OPTIONS
} from './types';
import {
  getClusterName,
  getReplicaSetName,
  isIgnored
} from './mongodb-utils';
import { promptUser } from './prompts';
import {
  ensureDir,
  readJsonFile,
  writeJsonFile,
  deleteFile,
  bytesToMB,
  formatDuration
} from './file-utils';
import { DEFAULT_CONFIG } from './constants';

/**
 * Verify that an index exists and matches expected specification
 */
async function verifyIndex(
  collection: Collection,
  indexName: string,
  expectedKey: Record<string, any>,
  expectedOptions: Record<string, any>
): Promise<boolean> {
  try {
    const allIndexes = await collection.indexes();
    const foundIndex = allIndexes.find(i => i.name === indexName);

    if (!foundIndex) {
      console.error(`  [SAFETY CHECK FAILED] Index '${indexName}' was not found.`);
      return false;
    }

    if (JSON.stringify(foundIndex.key) !== JSON.stringify(expectedKey)) {
      console.error(`  [SAFETY CHECK FAILED] Index '${indexName}' key mismatch.`);
      return false;
    }

    const finalOptsClean: Record<string, any> = {};
    for (const opt of VALID_INDEX_OPTIONS) {
      if (Object.prototype.hasOwnProperty.call(foundIndex, opt)) {
        finalOptsClean[opt] = foundIndex[opt];
      }
    }

    const optionsMatch = JSON.stringify(finalOptsClean) === JSON.stringify(expectedOptions);
    if (!optionsMatch) {
      console.error(`  [SAFETY CHECK FAILED] Index '${indexName}' options mismatch.`);
      return false;
    }

    console.log(`  [SAFETY CHECK PASSED] Index '${indexName}' is valid.`);
    return true;
  } catch (e) {
    console.error(`  [SAFETY CHECK FAILED] Error during verification for '${indexName}'.`, e);
    return false;
  }
}

/**
 * Phase 0: Cleanup orphaned temporary indexes
 */
async function cleanupOrphanedIndexes(db: Db, config: RebuildConfig): Promise<void> {
  console.log("--- Phase 0: Checking for orphaned temporary indexes ---");

  const orphanedIndexes: OrphanedIndex[] = [];
  const collectionNames = (await db.listCollections().toArray()).map(c => c.name);

  for (const collName of collectionNames) {
    const collection = db.collection(collName);
    const indexes = await collection.indexes();
    const orphansInColl = indexes.filter(idx => idx.name && idx.name.endsWith(config.coverSuffix!));

    if (orphansInColl.length > 0) {
      orphansInColl.forEach(o => {
        if (o.name) {
          orphanedIndexes.push({ collectionName: collName, indexName: o.name });
        }
      });
    }
  }

  if (orphanedIndexes.length === 0) {
    console.log("‚úÖ No orphaned indexes found.");
    return;
  }

  console.warn(`\n‚ö†Ô∏è Found ${orphanedIndexes.length} orphaned temporary index(es):`);
  orphanedIndexes.forEach(o =>
    console.log(`   - Collection: "${o.collectionName}", Index: "${o.indexName}"`)
  );

  if (config.safeRun) {
    const [responseChar, responseWord] = await promptUser(
      "\nProceed with cleanup? (y/n): ",
      ['yes', 'no'],
      'cleanup'
    );
    console.log(`User chose: [${responseWord}].`);
    if (responseChar === 'n') {
      throw new Error("User aborted cleanup operation.");
    }
  }

  console.log("-> Starting cleanup...");
  for (const orphan of orphanedIndexes) {
    await db.collection(orphan.collectionName).dropIndex(orphan.indexName);
    console.log(`  ‚úÖ Dropped: "${orphan.indexName}" from "${orphan.collectionName}"`);
  }
  console.log("‚úÖ Cleanup complete.");
}

/**
 * Rebuild indexes for a single collection
 */
async function rebuildCollectionIndexes(
  db: Db,
  collection: Collection,
  backedUpIndexes: IndexDocument[],
  indexStats: IndexStat[],
  state: RebuildState,
  paths: RebuildPaths,
  config: RebuildConfig
): Promise<{ status: string; log: CollectionLog }> {
  const collectionName = collection.collectionName;
  const collectionLog: CollectionLog = {
    startTime: new Date(),
    totalTimeSeconds: 0,
    initialSizeMb: 0,
    finalSizeMb: 0,
    reclaimedMb: 0,
    indexes: {}
  };

  // Filter processable indexes
  const processableIndexes = indexStats.filter(indexStat => {
    const idx = backedUpIndexes.find(i => i.name === indexStat.name);
    const isAlreadyCompleted = state.completed[collectionName]?.includes(idx?.name || '');

    if (isAlreadyCompleted && idx) {
      console.log(`\n‚ÑπÔ∏è Skipping index: "${idx.name}" (already marked as completed in state file).`);
    }

    return !isAlreadyCompleted &&
           idx &&
           !idx.unique &&
           idx.name !== '_id_' &&
           !isIgnored(idx.name, config.ignoredIndexes || []);
  });

  if (processableIndexes.length === 0) {
    console.log("\nNo indexes in this collection require rebuild.");
    return { status: 'skipped', log: collectionLog };
  }

  const sortedIndexes = processableIndexes.sort((a, b) => (b.size || 0) - (a.size || 0));

  console.log(`\nFound ${sortedIndexes.length} index(es) to rebuild in this collection (largest first):`);
  sortedIndexes.forEach(is =>
    console.log(`  - ${is.name} (~${bytesToMB(is.size || 0).toFixed(3)} MB)`)
  );

  let specifyIndexMode = false;
  if (config.safeRun) {
    const [responseChar, responseWord] = await promptUser(
      "\nProceed with these indexes? (yes/no/specify/skip collection) [y/n/s/b]: ",
      ['yes', 'no', 'specify', 'skip'],
      'indexes'
    );
    console.log(`User chose: [${responseWord}].`);

    if (responseChar === 'n') {
      throw new Error("User aborted the operation.");
    }
    if (responseChar === 'b') {
      console.log(`Skipping collection "${collectionName}".`);
      return { status: 'skipped', log: collectionLog };
    }
    if (responseChar === 's') {
      specifyIndexMode = true;
    }
  }

  for (const indexStat of sortedIndexes) {
    const originalName = indexStat.name;
    const idx = backedUpIndexes.find(i => i.name === originalName)!;

    if (specifyIndexMode) {
      const [continueWithIndex, continueWord] = await promptUser(
        `  -> Process index "${originalName}"? (y/n): `,
        ['yes', 'no'],
        'index-specify'
      );
      console.log(`  User chose: [${continueWord}].`);

      if (continueWithIndex === 'n') {
        console.log(`  Skipping index "${originalName}".`);
        continue;
      }
    }

    const initialSizeMb = bytesToMB(indexStat.size || 0);
    const indexLog: IndexLog = {
      startTime: new Date(),
      timeSeconds: 0,
      initialSizeMb,
      finalSizeMb: 0
    };

    console.log(`\n--- Processing index: "${originalName}" (~${initialSizeMb.toFixed(3)} MB) ---`);

    const originalKey = idx.key;
    const originalOptions: Record<string, any> = {};
    for (const opt of VALID_INDEX_OPTIONS) {
      if (Object.prototype.hasOwnProperty.call(idx, opt)) {
        originalOptions[opt] = idx[opt];
      }
    }

    const coveringKey = { ...originalKey };
    coveringKey[config.cheapSuffixField!] = 1;
    const coveringName = originalName + config.coverSuffix!;
    const coveringOptions: Record<string, any> = { name: coveringName };

    if (Object.prototype.hasOwnProperty.call(originalOptions, 'partialFilterExpression')) {
      coveringOptions.partialFilterExpression = originalOptions.partialFilterExpression;
    }

    console.log(`  [1/6] Calling createIndex for covering index '${coveringName}'.`);
    await collection.createIndex(coveringKey, coveringOptions);
    console.log(`  -> Command completed.`);

    console.log(`  [2/6] Calling verifyIndex for covering index...`);
    const expectedCoveringOptions: Record<string, any> = {};
    if (coveringOptions.partialFilterExpression) {
      expectedCoveringOptions.partialFilterExpression = coveringOptions.partialFilterExpression;
    }
    if (!await verifyIndex(collection, coveringName, coveringKey, expectedCoveringOptions)) {
      throw new Error(`Safety check failure for covering index.`);
    }

    console.log(`  [3/6] Calling dropIndex for old index '${originalName}'...`);
    await collection.dropIndex(originalName);
    console.log(`  -> Command completed.`);

    console.log(`  [4/6] Calling createIndex for final index '${originalName}'. THIS IS THE MAIN BUILD.`);
    await collection.createIndex(originalKey, { ...originalOptions, name: originalName });
    console.log(`  -> Command completed.`);

    console.log(`  [5/6] Calling verifyIndex for final rebuilt index...`);
    if (!await verifyIndex(collection, originalName, originalKey, originalOptions)) {
      throw new Error(`CRITICAL: Final index '${originalName}' is invalid.`);
    }

    console.log(`  [6/6] Calling dropIndex for covering index '${coveringName}'...`);
    await collection.dropIndex(coveringName);
    console.log(`  -> Command completed.`);

    // Get final index size using indexStats from db.collection.stats()
    const finalStats = await db.command({
      collStats: collection.collectionName,
      indexDetails: false
    });
    const finalIndexSize = finalStats.indexSizes?.[originalName] || 0;
    indexLog.finalSizeMb = bytesToMB(finalIndexSize);
    indexLog.timeSeconds = (new Date().getTime() - indexLog.startTime.getTime()) / 1000;
    collectionLog.indexes[originalName] = indexLog;

    if (!state.completed[collectionName]) {
      state.completed[collectionName] = [];
    }
    state.completed[collectionName].push(originalName);
    writeJsonFile(paths.stateFile, state);
    console.log(`  üíæ State file updated.`);

    console.log(`--- Rebuild for '${originalName}' complete in ${formatDuration(indexLog.timeSeconds)}. ---`);
  }

  // Calculate collection summary
  const finalCollectionStats = await db.command({
    collStats: collection.collectionName,
    indexDetails: false
  });
  let initialTotalSize = 0;
  for (const stat of indexStats) {
    initialTotalSize += (stat.size || 0);
  }

  collectionLog.initialSizeMb = bytesToMB(initialTotalSize);
  const finalIndexSizes = Object.values(finalCollectionStats.indexSizes || {}) as number[];
  collectionLog.finalSizeMb = bytesToMB(finalIndexSizes.reduce((sum, size) => sum + size, 0));
  collectionLog.reclaimedMb = collectionLog.initialSizeMb - collectionLog.finalSizeMb;
  collectionLog.totalTimeSeconds = (new Date().getTime() - collectionLog.startTime.getTime()) / 1000;

  console.log(`\n================ Collection "${collectionName}" complete in ${formatDuration(collectionLog.totalTimeSeconds)}. ================`);
  return { status: 'completed', log: collectionLog };
}

/**
 * Main rebuild function - accepts a Db instance and configuration
 * This is the library API that can be imported and used programmatically
 */
export async function rebuildIndexes(db: Db, config: RebuildConfig): Promise<DatabaseLog> {
  // Set defaults
  const fullConfig: Required<RebuildConfig> = {
    dbName: config.dbName,
    logDir: config.logDir || DEFAULT_CONFIG.LOG_DIR,
    runtimeDir: config.runtimeDir || DEFAULT_CONFIG.RUNTIME_DIR,
    coverSuffix: config.coverSuffix || DEFAULT_CONFIG.COVER_SUFFIX,
    cheapSuffixField: config.cheapSuffixField || DEFAULT_CONFIG.CHEAP_SUFFIX_FIELD,
    safeRun: config.safeRun !== undefined ? config.safeRun : DEFAULT_CONFIG.SAFE_RUN,
    specifiedCollections: config.specifiedCollections || [],
    ignoredCollections: config.ignoredCollections || [],
    ignoredIndexes: config.ignoredIndexes || [],
    performanceLogging: config.performanceLogging || DEFAULT_CONFIG.PERFORMANCE_LOGGING
  };

  let state: RebuildState = { completed: {} };
  const dbLog: DatabaseLog = {
    clusterName: 'unknown',
    dbName: fullConfig.dbName,
    startTime: new Date().toISOString(),
    totalTimeSeconds: 0,
    totalInitialSizeMb: 0,
    totalFinalSizeMb: 0,
    totalReclaimedMb: 0,
    collections: {},
    error: null
  };

  let paths: RebuildPaths = {
    stateFile: '',
    backupFile: '',
    logFile: ''
  };

  try {
    console.log(`\n### Starting UNIVERSAL index rebuild for database: "${fullConfig.dbName}" ###`);

    // Get cluster name
    const client = db.client as MongoClient;
    let clusterName = getClusterName(client);
    if (clusterName === 'unknown-cluster') {
      clusterName = await getReplicaSetName(db);
    }

    const timestamp = new Date().toISOString().replace(/:/g, '-').replace(/\..+/, '');
    dbLog.clusterName = clusterName;

    paths = {
      stateFile: `${fullConfig.runtimeDir}/${clusterName}_state.json`,
      backupFile: `${fullConfig.runtimeDir}/${clusterName}_backup_${timestamp}.json`,
      logFile: `${fullConfig.logDir}/${clusterName}_rebuild_log_${timestamp}.json`
    };

    ensureDir(fullConfig.runtimeDir);
    if (fullConfig.performanceLogging.enabled) {
      ensureDir(fullConfig.logDir);
    }

    // Load state if exists
    state = readJsonFile(paths.stateFile, { completed: {} });
    if (Object.keys(state.completed).length > 0) {
      console.log(`-> Loading state from previous run...`);
    }

    // Phase 0: Cleanup orphans
    await cleanupOrphanedIndexes(db, fullConfig);

    // Phase 2: Discover and backup collections
    console.log("\n--- Phase 2: Discovering and backing up all collections ---");
    const collectionsList = await db.listCollections().toArray();
    const allCollectionNames = collectionsList.map(c => c.name);
    const allIndexesBackup: Record<string, IndexDocument[]> = {};
    const collectionStatsList: CollectionInfo[] = [];

    for (const name of allCollectionNames) {
      const collection = db.collection(name);
      allIndexesBackup[name] = await collection.indexes() as IndexDocument[];

      const stats = await db.command({
        collStats: name,
        indexDetails: false
      });
      const indexSizes = stats.indexSizes || {};
      const indexStatsArray: IndexStat[] = Object.entries(indexSizes).map(([indexName, indexSize]) => ({
        name: indexName,
        size: indexSize as number
      }));

      collectionStatsList.push({
        name,
        indexStats: indexStatsArray,
        totalIndexSize: 0
      });
    }

    writeJsonFile(paths.backupFile, allIndexesBackup);
    console.log(`‚úÖ Index backup created at: "${paths.backupFile}"`);

    // Phase 3: Filter and sort collections
    console.log("\n--- Phase 3: Filtering and sorting target collections ---");
    let collectionsToProcess: CollectionInfo[];

    if (fullConfig.specifiedCollections.length > 0) {
      collectionsToProcess = collectionStatsList.filter(c =>
        fullConfig.specifiedCollections.includes(c.name)
      );
      if (fullConfig.ignoredCollections.length > 0) {
        console.warn("‚ö†Ô∏è WARNING: `specifiedCollections` is overriding `ignoredCollections`.");
      }
    } else {
      collectionsToProcess = collectionStatsList.filter(c =>
        !isIgnored(c.name, fullConfig.ignoredCollections)
      );
    }

    if (collectionsToProcess.length === 0) {
      throw new Error("No collections match the specified criteria.");
    }

    for (const coll of collectionsToProcess) {
      coll.totalIndexSize = coll.indexStats.reduce((sum, stat) => sum + (stat.size || 0), 0);
    }

    const sortedCollections = collectionsToProcess.sort((a, b) => b.totalIndexSize - a.totalIndexSize);

    console.log("\nCollections to be processed (largest first):");
    sortedCollections.forEach(c =>
      console.log(`  - ${c.name} (~${bytesToMB(c.totalIndexSize).toFixed(3)} MB)`)
    );

    let specifyCollectionMode = false;
    if (fullConfig.safeRun) {
      const [responseChar, responseWord] = await promptUser(
        "\nProceed with these collections? (yes/no/specify) [y/n/s]: ",
        ['yes', 'no', 'specify'],
        'collections'
      );
      console.log(`User chose: [${responseWord}].`);

      if (responseChar === 'n') {
        throw new Error("User aborted.");
      }
      if (responseChar === 's') {
        specifyCollectionMode = true;
      }
    }

    // Phase 4: Rebuild process
    console.log("\n--- Phase 4: Beginning rebuild process ---");
    for (const collectionInfo of sortedCollections) {
      if (specifyCollectionMode) {
        const [continueWithColl, continueWord] = await promptUser(
          `\nProcess collection "${collectionInfo.name}"? (y/n/end): `,
          ['yes', 'no', 'end'],
          'collection-specify'
        );
        console.log(`User chose: [${continueWord}].`);

        if (continueWithColl === 'n') {
          console.log(`Skipping collection "${collectionInfo.name}".`);
          continue;
        }
        if (continueWithColl === 'e') {
          throw new Error("User chose to end operation.");
        }
      }

      const collection = db.collection(collectionInfo.name);
      const result = await rebuildCollectionIndexes(
        db,
        collection,
        allIndexesBackup[collectionInfo.name],
        collectionInfo.indexStats,
        state,
        paths,
        fullConfig
      );

      if (result.status !== 'skipped') {
        dbLog.collections[collectionInfo.name] = result.log;
      }
    }

    // Calculate final summary
    dbLog.totalTimeSeconds = (new Date().getTime() - new Date(dbLog.startTime).getTime()) / 1000;

    let totalInitialSize = 0;
    let totalFinalSize = 0;
    for (const collName in dbLog.collections) {
      totalInitialSize += dbLog.collections[collName].initialSizeMb;
      totalFinalSize += dbLog.collections[collName].finalSizeMb;
    }

    dbLog.totalInitialSizeMb = totalInitialSize;
    dbLog.totalFinalSizeMb = totalFinalSize;
    dbLog.totalReclaimedMb = totalInitialSize - totalFinalSize;

    console.log("\n\n### ‚úÖ‚úÖ‚úÖ ALL-CLEAR: DATABASE REBUILD IS FULLY COMPLETE! ‚úÖ‚úÖ‚úÖ ###");

    if (fullConfig.performanceLogging.enabled) {
      console.log("\n--- PERFORMANCE SUMMARY ---");
      console.log(JSON.stringify(dbLog, null, 2));
      writeJsonFile(paths.logFile, dbLog);
      console.log(`\n‚úÖ Performance log saved to: "${paths.logFile}"`);
    }

    // Clean up state file on success
    deleteFile(paths.stateFile);
    console.log(`\n‚úÖ Run completed successfully. Removed state file: "${paths.stateFile}"`);

  } catch (e) {
    console.error(`\n\n‚ùå‚ùå‚ùå A CRITICAL ERROR OCCURRED! SCRIPT ABORTED. ‚ùå‚ùå‚ùå`);
    dbLog.error = e instanceof Error ? e.message : String(e);

    if (fullConfig.performanceLogging.enabled && paths.logFile) {
      try {
        writeJsonFile(paths.logFile, dbLog);
        console.log(`\n‚ö†Ô∏è Partial performance log with error saved to: "${paths.logFile}"`);
      } catch (writeErr) {
        console.error("Could not write partial log file.", writeErr);
      }
    }

    throw e;
  }

  return dbLog;
}

export { cleanupOrphanedIndexes };

